{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook\n",
    "- get raw data from CityBikes\n",
    "- make a table of trips between stations\n",
    "- use co-ordinates to get best routes between stations\n",
    "- connect to a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q geojson geoalchemy2 geopandas requests shapely pandas sqlalchemy psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import sys\n",
    "\n",
    "import geojson\n",
    "from geoalchemy2 import Geometry, WKTElement\n",
    "from geojson import Feature, Point, FeatureCollection\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import pandas as pd\n",
    "from sqlalchemy import *\n",
    "from shapely.geometry import Point\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://tor.publicbikesystem.net/ube/gbfs/v1/en/station_information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikeshare_stations = pd.DataFrame(json.loads(r.content)['data']['stations'])[['station_id', 'name', 'lat', 'lon']].astype({\n",
    "    'station_id': 'float64',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikeshare_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SQLAlchemy's engine to use\n",
    "engine = create_engine('postgresql://username:password@localhost:5432/atedeschi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Method using csv\n",
    "##df = pd.read_csv(\"bikeshare_stations.csv\", delimiter=\",\")\n",
    "\n",
    "df = bikeshare_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## geometry \n",
    "\n",
    "gdf = GeoDataFrame(\n",
    "    df.drop(['lon', 'lat'], axis=1),\n",
    "    crs={'init': 'epsg:4326'},\n",
    "    geometry=[Point(xy) for xy in zip(df.lon, df.lat)])\n",
    "\n",
    "def create_wkt_element(geom):\n",
    "    return WKTElement(geom.wkt, srid = 4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['geometry'] = gdf['geometry'].apply(create_wkt_element)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #   if_exists = replace: If table exists, drop it, recreate it, and insert data.\n",
    " #   if_exists = fail: If table exists, do nothing.\n",
    " #   if_exists = append: If table exists, insert data. Create if does not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf.to_sql(\"stations\", engine, if_exists='replace', index=False,\n",
    "                         dtype={'geometry': Geometry('POINT', 4326)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRID 4326 = WGS84 \n",
    "\n",
    "World Geodetic System. \n",
    "\n",
    "![WGS84](images/WGS84.png)\n",
    "\n",
    "Global Positioning System uses the World Geodetic System (WGS84) as its reference coordinate system.\n",
    "\n",
    "PostGIS opens up the ability to store your data in a single coordinate system such as WGS84 (SRID 4326), and when you need something like Area, Distance, or Length, you use a function to create that column from your datain a projected coordinate system that will give you a local interpretation of your data in units that you want.\n",
    "\n",
    "So for example, I could store students and schools in PostGIS both in WGS84/SRID:4326. When I want to calculate the distance between students and the schools they attend, I call a distance function on my geometry column, but also wrap a ST_Transform function around the geometry column first to 'project' the data into State Plane CO Central (SRID: 2877). This gives me a column for the distance of each student to their closest school in feet because SRID:2877 is a projected coordinate system that stores data in Feet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun fact ! ##\n",
    "\n",
    "Well-known text (WKT) is a text markup language for representing vector geometry objects on a map. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 and Q2 = hours and minutes\n",
    "#day/month/year\n",
    "\n",
    "#Q3 month/day/year hours and minutes\n",
    "#Q4 month/day/year hours minutes and seconds\n",
    "\n",
    "q1 = pd.read_csv(\"ridership1.csv\")\n",
    "q2 = pd.read_csv(\"ridership2.csv\")\n",
    "q3 = pd.read_csv(\"ridership3.csv\")\n",
    "q4 = pd.read_csv(\"ridership4.csv\")\n",
    "\n",
    "\n",
    "\n",
    "sids = pd.concat([q1,q2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sids = sids.drop(['from_station_id', 'from_station_name', 'trip_duration_seconds', 'trip_start_time', \\\n",
    "'trip_stop_time', 'user_type', 'trip_id'], axis  =1 )\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids = sids.drop_duplicates(keep = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids.columns = ['id', 'station_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1.drop(['from_station_id','to_station_id'], axis=1, inplace =True)\n",
    "q2.drop(['from_station_id','to_station_id'], axis=1, inplace =True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.concat([q1,q2])\n",
    "a = a.dropna(how='any') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times = a['trip_start_time'] \n",
    "a['trip_start_time'] = [datetime.strptime(time, \"%d/%m/%Y %H:%M\") for time in start_times]\n",
    "\n",
    "stop_times = a['trip_stop_time'] \n",
    "a['trip_stop_time'] = [datetime.strptime(time, \"%d/%m/%Y %H:%M\") for time in stop_times]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times = q3['trip_start_time'] \n",
    "q3['trip_start_time'] = [datetime.strptime(time, \"%m/%d/%Y %H:%M\") for time in start_times]\n",
    "\n",
    "stop_times = q3['trip_stop_time'] \n",
    "q3['trip_stop_time'] = [datetime.strptime(time, \"%m/%d/%Y %H:%M\") for time in stop_times]\n",
    "\n",
    "b = q3\n",
    "b = b.dropna(how='any') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4 = q4.dropna(how='any') \n",
    "\n",
    "start_times = q4['trip_start_time'] \n",
    "q4['trip_start_time'] = [datetime.strptime(time, \"%m/%d/%y %H:%M:%S\") for time in start_times]\n",
    "\n",
    "stop_times = q4['trip_stop_time'] \n",
    "q4['trip_stop_time'] = [datetime.strptime(time, \"%m/%d/%y %H:%M:%S\") for time in stop_times]\n",
    "\n",
    "\n",
    "c = q4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ct = pd.concat([a,b,c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con = engine.connect()\n",
    "sids = pd.read_sql_query(\"SELECT station_id, ST_Y(geometry) as lat, \\\n",
    "                         ST_X(geometry) as lon FROM stations \", con)\n",
    "#sids.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.merge(ct, sids, left_on = 'from_station_name', right_on = 'station_name')\n",
    "ct.drop(['station_name'], inplace = True, axis = 1)\n",
    "ct = ct.rename(columns = {'id': 'from_station_id'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.merge(ct, sids, left_on = 'to_station_name', right_on = 'station_name')\n",
    "ct.drop(['station_name'], inplace = True, axis = 1)\n",
    "ct = ct.rename(columns = {'id': 'to_station_id'})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.read_csv('clean_trips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ct = pd.read_csv('clean_trips.csv')\n",
    "ct.groupby(['from_station_id', 'to_station_id']).size().reset_index().rename(columns={0: 'count'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#con = engine.connect()\n",
    "sids = pd.read_sql_query(\"SELECT station_id, ST_Y(geometry) as lat, \\\n",
    "                         ST_X(geometry) as lon FROM stations \", con)\n",
    "\n",
    "sids['station_id'] = sids['station_id'].astype('int32')\n",
    "\n",
    "sids.head()\n",
    "\n",
    "sids.to_csv(\"sids.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.read_csv('clean_trips.csv')\n",
    "ct = ct.groupby(['from_station_id', 'to_station_id']).size().reset_index().rename(columns={0: 'count'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.merge(ct, sids, left_on = 'from_station_id', right_on = 'station_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs.rename(columns = {'lat': 'from_station_lat', 'lon': 'from_station_lon'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pd.merge(pairs, sids, left_on = 'to_station_id', right_on = 'station_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = pairs.rename(columns = {'lat': 'to_station_lat', 'lon': 'to_station_lon'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.drop(['station_id_x', 'station_id_y'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs.to_csv(\"pairs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " source =str(pairs['from_station_lon'][0]) + ',' + str(pairs['from_station_lat'][0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = []\n",
    "\n",
    "item = 0\n",
    "\n",
    "for index, pair in pairs.iterrows():\n",
    "    \n",
    "    source_coordinates = str(pair['from_station_lon']) + ',' + str(pair['from_station_lat']) + ';' \n",
    "    print(type(source_coordinates))\n",
    "    \n",
    "    dest_coordinates = str(pair['to_station_lon']) + ',' + str(pair['to_station_lat']) \n",
    "\n",
    "    item += 1\n",
    "    \n",
    "    url =  'http://router.project-osrm.org/route/v1/driving/'+source_coordinates+dest_coordinates\n",
    "\n",
    "    payload = {\"steps\":\"true\",\"geometries\":\"geojson\"}\n",
    "\n",
    "    response = requests.get(url,params=payload)\n",
    "\n",
    "    data = response.json()\n",
    "    #print(data)\n",
    "    print(item)\n",
    "    #print(data['routes'][0]['geometry'])\n",
    "    features.append(data['routes'][0]['geometry'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please iterate for all trips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_collection_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon, MultiPolygon, LineString\n",
    "new_features = []\n",
    "\n",
    "\n",
    "for feature in features:\n",
    "  line = LineString(feature['coordinates'])\n",
    "  \n",
    "  feature = Feature(\n",
    "    geometry=line,\n",
    "    properties={}\n",
    "  )\n",
    "\n",
    "  new_features.append(feature)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_collection = FeatureCollection(new_features)\n",
    "\n",
    "with open('paths.geojson', 'w') as f:\n",
    "  f.write(geojson.dumps(feature_collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT  \\\n",
    "n.area_name, \\\n",
    "SUM(ST_Length( \\\n",
    "    ST_Intersection(p.wkb_geometry::geography, \\\n",
    "                n.wkb_geometry::geography))) as length \\\n",
    "\\\n",
    "FROM neighborhoods n \\\n",
    "INNER JOIN paths p ON ST_Intersects(n.wkb_geometry, p.wkb_geometry) \\\n",
    "GROUP BY 1 \"\n",
    "\n",
    "con = engine.connect()\n",
    "output = pd.read_sql_query(query, con)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PostGIS exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "postgres://ubuntu:nyc@localhost/nyc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgres://ubuntu:nyc@localhost/nyc ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query  =  \"SELECT * FROM pg_catalog.pg_tables where schemaname = 'public'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ogr2ogr -f PostgreSQL PG:host='database-1.cpu2z0a5bugq.us-east-2.rds.amazonaws.com' port='5432' dbname='postgres' password ='postgres' user='postgres' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:postgres@database-1.cpu2z0a5bugq.us-east-2.rds.amazonaws.com:5432/postgres')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM pg_catalog.pg_tables where schemaname = 'public'\"\n",
    "\n",
    "pd.read_sql_query(query, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
